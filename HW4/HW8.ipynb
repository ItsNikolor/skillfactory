{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "clicks = []\n",
    "with open('c1.txt','r') as f:\n",
    "    for line in f:\n",
    "        clicks.append(reduce(lambda a,b:int(a)+int(b),line.split()))\n",
    "clicks1 = np.array(clicks)\n",
    "\n",
    "clicks = []\n",
    "with open('c2.txt','r') as f:\n",
    "    for line in f:\n",
    "        clicks.append(reduce(lambda a,b:int(a)+int(b),line.split()))\n",
    "clicks2 = np.array(clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699946 0.670108\n"
     ]
    }
   ],
   "source": [
    "ctr1 = []\n",
    "for i in range(len(clicks1)//1000):\n",
    "    ctr1.append((clicks1[i*1000:(i+1)*1000]>0).sum()/1000)\n",
    "ctr1 = np.array(ctr1)\n",
    "\n",
    "ctr2 = []\n",
    "for i in range(len(clicks2)//1000):\n",
    "    ctr2.append((clicks2[i*1000:(i+1)*1000]>0).sum()/1000)\n",
    "ctr2 = np.array(ctr2)\n",
    "\n",
    "print(ctr1.mean(),ctr2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASL = 1.0\n"
     ]
    }
   ],
   "source": [
    "def t_stat(x1,x2):\n",
    "    return (abs(x1.mean()-x2.mean())/\n",
    "            (math.sqrt(x1.std()/len(x1)+\n",
    "                       x2.std()/len(x2))))\n",
    " \n",
    "N = 1000\n",
    "t_base = 1.96\n",
    "\n",
    "count = 0\n",
    "for _ in range(N):\n",
    "    x1 = np.random.choice(ctr1,len(ctr1),replace=True)\n",
    "    x2 = np.random.choice(ctr2,len(ctr2),replace=True)\n",
    "    \n",
    "    if t_stat(x1,x2)>t_base:\n",
    "        count+=1\n",
    "\n",
    "print(f'ASL = {count/N}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***В выборках почти наверняка есть статистичкое различие в CTR метрике***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Теперь оставим только те запросы, куда были клики и посчитаем среди них количесто запросов в которые было более 1 (2) кликов***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7430114449213162 0.24616865671641794\n",
      "ASL = 1.0\n"
     ]
    }
   ],
   "source": [
    "ctr1 = []\n",
    "clicks1 = clicks1[clicks1>0]\n",
    "for i in range(len(clicks1)//1000):\n",
    "    ctr1.append((clicks1[i*1000:(i+1)*1000]>1).sum()/1000)\n",
    "ctr1 = np.array(ctr1)\n",
    "\n",
    "ctr2 = []\n",
    "clicks2 = clicks2[clicks2>0]\n",
    "for i in range(len(clicks2)//1000):\n",
    "    ctr2.append((clicks2[i*1000:(i+1)*1000]>1).sum()/1000)\n",
    "ctr2 = np.array(ctr2)\n",
    "print(ctr1.mean(),ctr2.mean())\n",
    "\n",
    "N = 1000\n",
    "t_base = 1.96\n",
    "\n",
    "count = 0\n",
    "for _ in range(N):\n",
    "    x1 = np.random.choice(ctr1,len(ctr1),replace=True)\n",
    "    x2 = np.random.choice(ctr2,len(ctr2),replace=True)\n",
    "    \n",
    "    if t_stat(x1,x2)>t_base:\n",
    "        count+=1\n",
    "\n",
    "print(f'ASL = {count/N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999685264663805 0.038617910447761195\n",
      "ASL = 1.0\n"
     ]
    }
   ],
   "source": [
    "ctr1 = []\n",
    "for i in range(len(clicks1)//1000):\n",
    "    ctr1.append((clicks1[i*1000:(i+1)*1000]>2).sum()/1000)\n",
    "ctr1 = np.array(ctr1)\n",
    "\n",
    "ctr2 = []\n",
    "for i in range(len(clicks2)//1000):\n",
    "    ctr2.append((clicks2[i*1000:(i+1)*1000]>2).sum()/1000)\n",
    "ctr2 = np.array(ctr2)\n",
    "print(ctr1.mean(),ctr2.mean())\n",
    "\n",
    "N = 1000\n",
    "t_base = 1.96\n",
    "\n",
    "count = 0\n",
    "for _ in range(N):\n",
    "    x1 = np.random.choice(ctr1,len(ctr1),replace=True)\n",
    "    x2 = np.random.choice(ctr2,len(ctr2),replace=True)\n",
    "    \n",
    "    if t_stat(x1,x2)>t_base:\n",
    "        count+=1\n",
    "\n",
    "print(f'ASL = {count/N}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Выборки отличаются в обеих этих метриках и это отличие статистически значимо***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Выбрать лучший сплит имея только клики довольно сложно, но я попробую<br><br>\n",
    "&emsp;Среднее CTR больше у первого сплита. Это значит, что в первом сплите появилось больше запросов на которые мы отвечаем достаточно хорошо, чтобы пользователь на него кликнул. Но этого недостаточно. По сути мы повысили полноту, но ничего не знаем о точности. Возможно, что на то, на что мы отвечали раньше хорошо, теперь мы отвечаем плохо. Да и впринципе то, что пользователь кликает на документ в общем случае не означает, что этот документ релевантен<br><br>\n",
    "&emsp;Для того, чтобы оценить точность я буду исходить из следующего предположения - в идеальном поисковике пользователь кликает лишь на один документ. Почему это так? Разберём возможные ситуации: пользователь кликнул на один документ и ушёл. Есть 3 возможности:<br>\n",
    "   &emsp;&emsp;1) Он нашёл, что искал и ушёл<br>\n",
    "   &emsp;&emsp;2) Он не нашёл, что искал, но все остальные наши результаты совсем плохие, поэтому он просто ушёл<br>\n",
    "   &emsp;&emsp;3) Рандом. Отошёл от компьютера, забыл что искал, умер за клавиатурой<br>\n",
    "&emsp;Считаем, что шанс 3) довольно мал. Чем лучше наш поисковик, тем меньше вероятность 2). Таким образом, если у нас довольно неплохой поисковик, то 1 клик обычно означает, что поиск отработал хорошо.<br><br>\n",
    "   &emsp;Теперь допустим пользователь кликнул на много документов. Опять 3 возможности:<br>\n",
    "   &emsp;&emsp;1) Пользователь собирает много разной информации<br>\n",
    "   &emsp;&emsp;2) Пользователь всё никак не может найти ответ на свой вопрос<br>\n",
    "   &emsp;&emsp;3) Рандом. Кошка по клавиатуре ходит и кликает на сайты<br>\n",
    "&emsp;Считаем, что шанс 3) довольно мал. Обычно пользователи нетерпеливые и не любят долго искать информацию, поэтому будем считать, что 1) не очень частотный. Таким образом в среднем много кликов означает, что пользователь не может найти ответ на свой вопрос. В интернете ответ почти наверняка есть, а значит проблема в поисковике.<br>\n",
    "   &emsp;Таким образом мы хотим, чтобы было как можно больше запросов в которых мало кликов и как можно меньше запросов в которых кликов много. Эту статистику я уже посчитал выше и по ней видно, что во втором сплите количество запросов с более, чем одним кликом ЗНАЧИТЕЛЬНО меньше, чем в первом сплите. По CTR различие не такое фундаментальное, поэтому я считаю, что лучшим является второй сплит***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ: лучшим является второй сплит***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
